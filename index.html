<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
	<link rel="shortcut icon" href="./pic/cuhk.ico">
	<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
	<meta name="keywords" content="Jie Yang">
	<meta name="description" content="Jie Yang's home page">
	<meta name="google-site-verification" content="xg04VgCH_1GseFDVDJUDOU2fWPkMU61koxePfxI9L2U" />
	<link rel="stylesheet" href="jemdoc.css" type="text/css">
	<title>Jie Yang&#39;s Homepage</title>
</head>
<body>
	<!-- <nav class="navbar navbar-dark navbar-expand-lg fixed-top">
		<div id="layout-menu">
			<a href="#publication">Publication</a>
			<a href="#experience">Experience</a>
			<a href="#service">Service</a>
			<a href="#presentation">Presentation</a>
			<a href="#award">Award</a>
			<a href="#patent">Patent</a>
			<a href="#teaching">Teaching</a>
		</div>
	</nav> -->
<div id="layout-content" style="margin-top:25px">
 <a href="https://github.com/yangjie-cv" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FD6C6C; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1></h1>
					<h1>Jie Yang &nbsp;&nbsp;<font face="Arial">杨杰</font></h1>
				</div>

				<h3>PhD Student</h3>
				<p>
					Computer and Information Engineering<br>
					The Chinese University of Hong Kong, Shenzhen<br>
					<br>
					Email: <a href="mailto:jieyang5@link.cuhk.edu.cn">jieyang5@link.cuhk.edu.cn</a><br>
				</p>
				<p>
					<a href="https://scholar.google.com/citations?user=UVzG9IcAAAAJ&hl=zh-CN"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/yangjie-cv"><img src="./pic/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
				</p>
			</td>
			<td>
				<img src="./pic/yangjie.jpg" border="0" width="300" style="margin-right: 50px;"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2>Biography</h2>
<p>
	I am a second-year PhD student in the	<a href="http://sse.cuhk.edu.cn/">School of Science and Engineering</a>,
	<a href="http://www.cuhk.edu.cn/">The Chinese University of Hong Kong, Shenzhen</a>, 
	co-supervised by <a href="http://www.zhangruimao.site/">Prof. Ruimao Zhang</a> and <a href="https://mypage.cuhk.edu.cn/academics/lizhen/">Prof. Zhen Li</a>. Currently, I am an intern of computer vision at International Digital Economy Academy (IDEA), advised by <a href="https://ailingzeng.site/">Researcher Ailing Zeng</a> and <a href="https://www.leizhang.org/">Prof. Lei Zhang</a>.
</p>

<p>My research interest lies in human-centric visual understanding, perception and generation. </p>


<h2>News</h2>
<ul>
	<li>
		[2023.03.02] Two papers are accepted by MIDL2023 and one is rated as the oral presentation.
	</li>
	<li>
		[2023.02.28] One paper is accepted by CVPR2023.
	</li>
	<li>
		[2023.01.21] One paper is accepted by ICLR2023.
	</li>
	<li>
		[2022.09.17] One paper is accepted by NeurIPS2022.
	</li>
	<!-- <li>
		[08/2019] We won <p style="color: red; display: inline;">The Third Place</p> in the Task Challenge of <a href="http://robo-tend.ustc.edu.cn/">IJCAI-2019 Eldercare Robot Challenges</a>!
	</li>

	<li>
		[06/2019] Fortunate to receive <p style="color: red; display: inline;">Provincial-level Merit Student Award</p> of Henan (Top 0.3%).
	</li>

	<li>
		[05/2019] We won <p style="color: red; display: inline;">The Champion</p> in the @Home League of <a href="http://www.tsinghua-tj.org/news/3102.html">RoboCup Asia-Pacific (Tianjin Invitational Tournament)</a>!
	</li> -->

</ul>
		<h2> Selected Publications [<a href="https://scholar.google.com/citations?user=UVzG9IcAAAAJ&hl=zh-CN">Google Scholar</a>]</h2>
		<table id="tbPublications" width="100%">
			<tbody>

								<tr>
					<td width="270">
						<img src="./indexpics/SST.png" width="225px" style="box-shadow: 4px 4px 8px #888"
							class="center">
					</td>
					<td><b>Semantic Human Parsing via Scalable Semantic Transfer over Multiple Label Domains</b><br>
						<b>Jie Yang</b>, Chaoqun Wang, Zhen Li, Junle Wang, Ruimao Zhang*.<br>
						<em>Proc. of IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023.
		
					</td>
				</tr>
				
												<tr>
					<td width="270">
						<img src="./indexpics/edpose.png" width="225px" style="box-shadow: 4px 4px 8px #888"
							class="center">
					</td>
					<td><b><p><a href="https://arxiv.org/pdf/2302.01593">Explicit Box Detection Unifies End-to-End Multi-Person Pose Estimation</b><br></a>
						<b>Jie Yang</b>, Ailing Zeng*, Shilong Liu, Feng Li, Ruimao Zhang*, Lei Zhang.<br>
						<em>Proc. of International Conference on Learning Representations (ICLR)</em>, 2023.
		
					</td>
				</tr>
				
				
				<tr>
					<td width="270">
						<img src="./indexpics/midl.png" width="225px" style="box-shadow: 4px 4px 8px #888"
							class="center">
					</td>
					<td><b>Toward Unpaired Multi-modal Medical Image Segmentation via Learning Structured Semantic Consistency</b><br>
						<b>Jie Yang</b>, Ye Zhu, Chaoqun Wang, Zhen Li, Ruimao Zhang*.<br>
						<em>Proc. of Conference on Medical Imaging with Deep Learning (MIDL)</em>, 2023.
		
					</td>
				</tr>

				<tr>
					<td width="270">
						<img src="./indexpics/semi.png" width="225px" style="box-shadow: 4px 4px 8px #888"
							class="center">
					</td>
					<td><b>Inherent Consistent Learning for Accurate Semi-supervised Medical Image Segmentation</b><br>
						Ye Zhu, <b>Jie Yang</b>, Siqi Liu, Ruimao Zhang*.<br>
						<em>Proc. of Conference on Medical Imaging with Deep Learning (MIDL)</em>, <b><span style="color: red">Oral</span></b>, 2023. 
					</td>
				</tr>





				<tr>&nbsp</tr>
				<tr>&nbsp</tr>
				<tr>&nbsp</tr>



			</tbody>
		</table>


	<h2>Honors &amp; Awards</h2>
		<ul>

			<li>
				<tr>
					<td> National Scholarship, 2018</td>
				</tr>
			</li>
		</ul>




		<div id="footer">
			<div id="footer-text"></div>
		</div>
		<p>
			<center>
				<div id="clustrmaps-widget" style="width:40%">
					<script type='text/javascript' id='clustrmaps'
						src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=400&t=tt&d=yqzHjRzsBJQtkz3lH1jgeuQAOnTiZWl3UFnWM5FeXZM&cmo=ff0000&cmn=ffb800&ct=ffffff'></script>
				</div>

				<br>&copy; Jie Yang | Last updated: March 2023

			</center>
		</p>


	</div>

</body>

</html>
</body>

</html>
